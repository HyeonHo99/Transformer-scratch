# Transformer-scratch
### Pytorch Implementation of Transformer Model Presented on ["Attention Is All You Need"](https://arxiv.org/pdf/1706.03762.pdf)
<img src="imgs/attention-title.PNG" width="500" height="300"></img>

## The Transformer - Model Architecture
<img src="imgs/transformer-architecture.PNG" width="300" height="700"></img>
-
-


**Mechanism of Multi-Head Attention**

![image](https://user-images.githubusercontent.com/69974410/185332384-fae1ea8f-3f97-4e14-8072-04a19d0176d7.png)

![image](https://user-images.githubusercontent.com/69974410/185332509-f452d2d9-5037-4358-83a9-acfa70357756.png)
